# Repo Expert Agents â€” Configuration
# Copy to config.yaml and customize for your repos.
# API key: set LETTA_API_KEY in your .env file.

letta:
  model: openai/gpt-4.1
  # fast_model: openai/gpt-4.1-mini   # Optional model used by ask routing=auto|speed
  embedding: openai/text-embedding-3-small

# Optional global defaults (all can be overridden per-repo)
defaults:
  max_file_size_kb: 50        # Skip files larger than this
  memory_block_limit: 5000    # Max chars per core memory block
  bootstrap_on_create: true   # Auto-analyze codebase on setup
  # ask_timeout_ms: 20000      # Default timeout for single-agent ask requests
  # fast_ask_timeout_ms: 8000  # Timeout when fast model path is selected
  # cache_ttl_ms: 180000       # In-memory answer cache TTL (ms)
  # chunking: raw             # Chunking strategy: "raw" (default) or "tree-sitter"
  # tools:                    # Letta tools for all agents (per-repo overrides)
  #   - send_message_to_agents_matching_tags  # Cross-agent broadcast

repos:
  # Each key becomes the agent name (repo-expert-<key>)
  my-app:
    path: ~/repos/my-app                       # Absolute or ~ path to repo
    description: "React Native mobile app"     # Used in agent persona
    extensions: [.ts, .tsx, .js, .jsx, .json]  # File types to index
    ignore_dirs: [node_modules, .git, dist]    # Directories to skip
    tags: [frontend, mobile]                   # For cross-agent discovery
    # Optional: custom persona (auto-generated from description if omitted)
    # persona: |
    #   I am an expert on the mobile app.
    #   I know every screen, component, and navigation flow.

  # backend:
  #   path: ~/repos/backend
  #   description: "Node.js backend API"
  #   extensions: [.ts, .js, .sql, .yaml, .json]
  #   ignore_dirs: [node_modules, .git, dist]
  #   tags: [backend, api]
